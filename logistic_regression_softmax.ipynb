{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train Data\n",
    "x = []\n",
    "y = []\n",
    "filename = 'cifar-10-batches-py/data_batch_%d'\n",
    "for b in range(1,6):\n",
    "    f = os.path.join(filename  % (b, ))\n",
    "    with open(f, 'r') as f:\n",
    "        datadict = pickle.load(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "    x.append(X)\n",
    "    y.append(Y)    \n",
    "    \n",
    "x_train = np.concatenate(x)\n",
    "y_train = np.concatenate(y)\n",
    "\n",
    "#Load Test Data\n",
    "f = 'cifar-10-batches-py/test_batch'\n",
    "with open(f, 'r') as f:\n",
    "    datadict = pickle.load(f)\n",
    "    x_test = datadict['data']\n",
    "    y_test = datadict['labels']\n",
    "    x_test = x_test.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "    y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get RAW Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_training = 49000\n",
    "num_val = 1000\n",
    "num_test = 10000\n",
    "\n",
    "# subsample the data for validation set\n",
    "mask = xrange(num_training, num_training + num_val)\n",
    "x_val_raw = x_train[mask]\n",
    "y_val_raw = y_train[mask]\n",
    "\n",
    "mask = xrange(num_training)\n",
    "x_train_raw = x_train[mask]\n",
    "y_train_raw = y_train[mask]\n",
    "\n",
    "mask = xrange(num_test)\n",
    "x_test_raw = x_test[mask]\n",
    "y_test_raw = y_test[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing: reshape the image data into rows\n",
    "x_train = np.reshape(x_train_raw, (x_train_raw.shape[0], -1)) # [49000, 3072]\n",
    "x_val = np.reshape(x_val_raw, (x_val_raw.shape[0], -1)) # [1000, 3072]\n",
    "x_test = np.reshape(x_test_raw, (x_test_raw.shape[0], -1)) # [10000, 3072]\n",
    "    \n",
    "# Normalize the data: subtract the mean image\n",
    "mean_image = np.mean(x_train, axis = 0)\n",
    "x_train -= mean_image\n",
    "x_val -= mean_image\n",
    "x_test -= mean_image\n",
    "    \n",
    "# Add bias dimension and transform into columns\n",
    "x_train = np.hstack([x_train, np.ones((x_train.shape[0], 1))]).T\n",
    "x_val = np.hstack([x_val, np.ones((x_val.shape[0], 1))]).T\n",
    "x_test = np.hstack([x_test, np.ones((x_test.shape[0], 1))]).T\n",
    "\n",
    "y_train = y_train_raw\n",
    "y_val = y_val_raw\n",
    "y_test = y_test_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainin Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0/1000: loss 1553.288803\n",
      "iteration 100/1000: loss 2.129240\n",
      "iteration 200/1000: loss 2.174545\n",
      "iteration 300/1000: loss 2.176543\n",
      "iteration 400/1000: loss 2.130676\n",
      "iteration 500/1000: loss 2.074817\n",
      "iteration 600/1000: loss 2.153908\n",
      "iteration 700/1000: loss 2.188529\n",
      "iteration 800/1000: loss 2.166894\n",
      "iteration 900/1000: loss 2.202306\n",
      "Training accuracy: 0.296388\n",
      "Validation accuracy: 0.306000\n"
     ]
    }
   ],
   "source": [
    "from linear_classifier import Softmax\n",
    "\n",
    "softmax_sgd = Softmax()\n",
    "losses_sgd = softmax_sgd.train(x_train, y_train, method='sgd', batch_size=200, learning_rate=1e-6,\n",
    "              reg = 1e5, num_iters=1000, verbose=True, vectorized=True)\n",
    "\n",
    "y_train_pred_sgd = softmax_sgd.predict(x_train)[0]\n",
    "print 'Training accuracy: %f' % (np.mean(y_train == y_train_pred_sgd))\n",
    "y_val_pred_sgd = softmax_sgd.predict(x_val)[0]\n",
    "print 'Validation accuracy: %f' % (np.mean(y_val == y_val_pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration is 1/5\n",
      "The current iteration is 2/5\n",
      "The current iteration is 3/5\n",
      "The current iteration is 4/5\n",
      "The current iteration is 5/5\n",
      "learning rate 1.000000e-08 and regularization 1.000000e+03, \n",
      "     the training accuracy is: 0.125122 and validation accuracy is: 0.117000.\n",
      "\n",
      "learning rate 1.000000e-08 and regularization 2.575000e+04, \n",
      "     the training accuracy is: 0.147918 and validation accuracy is: 0.156000.\n",
      "\n",
      "learning rate 1.000000e-08 and regularization 5.050000e+04, \n",
      "     the training accuracy is: 0.142571 and validation accuracy is: 0.149000.\n",
      "\n",
      "learning rate 1.000000e-08 and regularization 7.525000e+04, \n",
      "     the training accuracy is: 0.147837 and validation accuracy is: 0.150000.\n",
      "\n",
      "learning rate 1.000000e-08 and regularization 1.000000e+05, \n",
      "     the training accuracy is: 0.149082 and validation accuracy is: 0.154000.\n",
      "\n",
      "learning rate 2.507500e-06 and regularization 1.000000e+03, \n",
      "     the training accuracy is: 0.394918 and validation accuracy is: 0.398000.\n",
      "\n",
      "learning rate 2.507500e-06 and regularization 2.575000e+04, \n",
      "     the training accuracy is: 0.310102 and validation accuracy is: 0.306000.\n",
      "\n",
      "learning rate 2.507500e-06 and regularization 5.050000e+04, \n",
      "     the training accuracy is: 0.290286 and validation accuracy is: 0.282000.\n",
      "\n",
      "learning rate 2.507500e-06 and regularization 7.525000e+04, \n",
      "     the training accuracy is: 0.284857 and validation accuracy is: 0.289000.\n",
      "\n",
      "learning rate 2.507500e-06 and regularization 1.000000e+05, \n",
      "     the training accuracy is: 0.277347 and validation accuracy is: 0.282000.\n",
      "\n",
      "learning rate 5.005000e-06 and regularization 1.000000e+03, \n",
      "     the training accuracy is: 0.374408 and validation accuracy is: 0.374000.\n",
      "\n",
      "learning rate 5.005000e-06 and regularization 2.575000e+04, \n",
      "     the training accuracy is: 0.260857 and validation accuracy is: 0.268000.\n",
      "\n",
      "learning rate 5.005000e-06 and regularization 5.050000e+04, \n",
      "     the training accuracy is: 0.251020 and validation accuracy is: 0.281000.\n",
      "\n",
      "learning rate 5.005000e-06 and regularization 7.525000e+04, \n",
      "     the training accuracy is: 0.228306 and validation accuracy is: 0.227000.\n",
      "\n",
      "learning rate 5.005000e-06 and regularization 1.000000e+05, \n",
      "     the training accuracy is: 0.175878 and validation accuracy is: 0.180000.\n",
      "\n",
      "learning rate 7.502500e-06 and regularization 1.000000e+03, \n",
      "     the training accuracy is: 0.290939 and validation accuracy is: 0.282000.\n",
      "\n",
      "learning rate 7.502500e-06 and regularization 2.575000e+04, \n",
      "     the training accuracy is: 0.180592 and validation accuracy is: 0.183000.\n",
      "\n",
      "learning rate 7.502500e-06 and regularization 5.050000e+04, \n",
      "     the training accuracy is: 0.171122 and validation accuracy is: 0.147000.\n",
      "\n",
      "learning rate 7.502500e-06 and regularization 7.525000e+04, \n",
      "     the training accuracy is: 0.132163 and validation accuracy is: 0.122000.\n",
      "\n",
      "learning rate 7.502500e-06 and regularization 1.000000e+05, \n",
      "     the training accuracy is: 0.095184 and validation accuracy is: 0.087000.\n",
      "\n",
      "learning rate 1.000000e-05 and regularization 1.000000e+03, \n",
      "     the training accuracy is: 0.270388 and validation accuracy is: 0.283000.\n",
      "\n",
      "learning rate 1.000000e-05 and regularization 2.575000e+04, \n",
      "     the training accuracy is: 0.161041 and validation accuracy is: 0.162000.\n",
      "\n",
      "learning rate 1.000000e-05 and regularization 5.050000e+04, \n",
      "     the training accuracy is: 0.129735 and validation accuracy is: 0.121000.\n",
      "\n",
      "learning rate 1.000000e-05 and regularization 7.525000e+04, \n",
      "     the training accuracy is: 0.112204 and validation accuracy is: 0.108000.\n",
      "\n",
      "learning rate 1.000000e-05 and regularization 1.000000e+05, \n",
      "     the training accuracy is: 0.119592 and validation accuracy is: 0.125000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using validation set to tuen hyperparameters, i.e., learning rate and regularization strength\n",
    "learning_rates = [1e-5, 1e-8]\n",
    "regularization_strengths = [10e2, 10e4]\n",
    "\n",
    "# Result is a dictionary mapping tuples of the form (learning_rate, regularization_strength) \n",
    "# to tuples of the form (training_accuracy, validation_accuracy). The accuracy is simply the fraction\n",
    "# of data points that are correctly classified.\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "# Choose the best hyperparameters by tuning on the validation set\n",
    "i = 0\n",
    "interval = 5\n",
    "for learning_rate in np.linspace(learning_rates[0], learning_rates[1], num=interval):\n",
    "    i += 1\n",
    "    print 'The current iteration is %d/%d' % (i, interval)\n",
    "    for reg in np.linspace(regularization_strengths[0], regularization_strengths[1], num=interval):\n",
    "        softmax = Softmax()\n",
    "        softmax.train(x_train, y_train, method='sgd', batch_size=200, learning_rate=learning_rate,\n",
    "              reg = reg, num_iters=700, verbose=False, vectorized=True)\n",
    "        y_train_pred = softmax.predict(x_train)[0]\n",
    "        y_val_pred = softmax.predict(x_val)[0]\n",
    "        train_accuracy = np.mean(y_train == y_train_pred)\n",
    "        val_accuracy = np.mean(y_val == y_val_pred)\n",
    "        results[(learning_rate, reg)] = (train_accuracy, val_accuracy)\n",
    "        if val_accuracy > best_val:\n",
    "            best_val = val_accuracy\n",
    "            best_softmax = softmax\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# Print out the results\n",
    "for learning_rate, reg in sorted(results):\n",
    "    train_accuracy,val_accuracy = results[(learning_rate, reg)]\n",
    "    print 'learning rate %e and regularization %e, \\n \\\n",
    "    the training accuracy is: %f and validation accuracy is: %f.\\n' % (learning_rate, reg, train_accuracy, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test best logistic classifier on test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: 0.392300\n"
     ]
    }
   ],
   "source": [
    "y_test_predict_result = best_softmax.predict(x_test)\n",
    "y_test_predict = y_test_predict_result[0]\n",
    "test_accuracy = np.mean(y_test == y_test_predict)\n",
    "print 'The test accuracy is: %f' % test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
